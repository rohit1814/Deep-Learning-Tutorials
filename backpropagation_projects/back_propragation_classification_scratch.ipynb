{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4b579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99650b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  placed\n",
       "0     8              8       1\n",
       "1     7              9       1\n",
       "2     6             10       0\n",
       "3     5              5       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[8,8,1],[7,9,1],[6,10,0],[5,5,0]], columns=['cgpa', 'profile_score', 'placed'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e621db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "  \n",
    "  np.random.seed(3)\n",
    "  parameters = {}\n",
    "  L = len(layer_dims)         \n",
    "\n",
    "  for l in range(1, L):\n",
    "\n",
    "    parameters['W' + str(l)] = np.ones((layer_dims[l-1], layer_dims[l]))*0.1\n",
    "    parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "      \n",
    "\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c0e5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def sigmoid(Z):\n",
    "  \n",
    "  A = 1/(1+np.exp(-Z))\n",
    "\n",
    "  return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e256433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "  \n",
    "  Z = np.dot(W.T, A_prev) + b\n",
    "\n",
    "  A = sigmoid(Z)\n",
    "  \n",
    "  return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb5f7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L-layer feed forward\n",
    "\n",
    "def L_layer_forward(X, parameters):\n",
    "\n",
    "  A = X\n",
    "  L = len(parameters) // 2                  # number of layers in the neural network\n",
    "  \n",
    "  for l in range(1, L+1):\n",
    "    A_prev = A \n",
    "    Wl = parameters['W' + str(l)]\n",
    "    bl = parameters['b' + str(l)]\n",
    "    #print(\"A\"+str(l-1)+\": \", A_prev)\n",
    "    #print(\"W\"+str(l)+\": \", Wl)\n",
    "    #print(\"b\"+str(l)+\": \", bl)\n",
    "    #print(\"--\"*20)\n",
    "\n",
    "    A = linear_forward(A_prev, Wl, bl)\n",
    "    #print(\"A\"+str(l)+\": \", A)\n",
    "    #print(\"**\"*20)\n",
    "          \n",
    "  return A,A_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efd3fa",
   "metadata": {},
   "source": [
    "##### As loss function has been changed to Binary Cross Entropy, the backpropagation also needs to be changed accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As loss function has been changed to Binary Cross Entropy, the backpropagation also needs to be changed accordingly.\n",
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.0001 * (y - y_hat)*A1[0][0])\n",
    "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat)*A1[1][0])\n",
    "  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat))\n",
    "\n",
    "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[0][0])\n",
    "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[1][0])\n",
    "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0]))\n",
    "\n",
    "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[0][0])\n",
    "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[1][0])\n",
    "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46baa2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for this student -  0.613402628898913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10000513, 0.10000513],\n",
       "        [0.10000513, 0.10000513]]),\n",
       " 'b1': array([[6.41054186e-07],\n",
       "        [6.41054186e-07]]),\n",
       " 'W2': array([[0.10003815],\n",
       "        [0.10003815]]),\n",
       " 'b2': array([[0.100084]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['placed']].values[0][0]\n",
    "\n",
    "# Parameter initialization\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "print('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a70c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for this student -  0.568725622654268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10000937, 0.10001059],\n",
       "        [0.10000937, 0.10001059]]),\n",
       " 'b1': array([[1.24770113e-06],\n",
       "        [1.24770113e-06]]),\n",
       " 'W2': array([[0.10007424],\n",
       "        [0.10007424]]),\n",
       " 'b2': array([[0.10011761]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[1].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['placed']].values[1][0]\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "print('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be05f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for this student -  0.8353333695154365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10000463, 0.10000267],\n",
       "        [0.10000463, 0.10000267]]),\n",
       " 'b1': array([[4.56125378e-07],\n",
       "        [4.56135584e-07]]),\n",
       " 'W2': array([[0.10002712],\n",
       "        [0.10002712]]),\n",
       " 'b2': array([[0.09997049]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[2].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['placed']].values[2][0]\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "print('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b453af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for this student -  0.8238180133031612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.09999911, 0.09999716],\n",
       "        [0.09999911, 0.09999716]]),\n",
       " 'b1': array([[-6.47175329e-07],\n",
       "        [-6.47175081e-07]]),\n",
       " 'W2': array([[0.09998609],\n",
       "        [0.09998609]]),\n",
       " 'b2': array([[0.09992997]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[3].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['placed']].values[3][0]\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "print('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f45b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  1 Loss -  0.7103199085929446\n",
      "Epoch -  2 Loss -  0.699170289280263\n",
      "Epoch -  3 Loss -  0.6991679314811485\n",
      "Epoch -  4 Loss -  0.6991655746710999\n",
      "Epoch -  5 Loss -  0.6991632188496667\n",
      "Epoch -  6 Loss -  0.699160864016399\n",
      "Epoch -  7 Loss -  0.6991585101708473\n",
      "Epoch -  8 Loss -  0.699156157312562\n",
      "Epoch -  9 Loss -  0.6991538054410936\n",
      "Epoch -  10 Loss -  0.6991514545559935\n",
      "Epoch -  11 Loss -  0.6991491046568126\n",
      "Epoch -  12 Loss -  0.6991467557431024\n",
      "Epoch -  13 Loss -  0.6991444078144144\n",
      "Epoch -  14 Loss -  0.6991420608703007\n",
      "Epoch -  15 Loss -  0.6991397149103133\n",
      "Epoch -  16 Loss -  0.6991373699340042\n",
      "Epoch -  17 Loss -  0.6991350259409265\n",
      "Epoch -  18 Loss -  0.6991326829306324\n",
      "Epoch -  19 Loss -  0.6991303409026751\n",
      "Epoch -  20 Loss -  0.699127999856608\n",
      "Epoch -  21 Loss -  0.6991256597919842\n",
      "Epoch -  22 Loss -  0.6991233207083575\n",
      "Epoch -  23 Loss -  0.6991209826052818\n",
      "Epoch -  24 Loss -  0.699118645482311\n",
      "Epoch -  25 Loss -  0.6991163093389996\n",
      "Epoch -  26 Loss -  0.699113974174902\n",
      "Epoch -  27 Loss -  0.6991116399895729\n",
      "Epoch -  28 Loss -  0.6991093067825676\n",
      "Epoch -  29 Loss -  0.699106974553441\n",
      "Epoch -  30 Loss -  0.6991046433017485\n",
      "Epoch -  31 Loss -  0.6991023130270458\n",
      "Epoch -  32 Loss -  0.699099983728889\n",
      "Epoch -  33 Loss -  0.6990976554068338\n",
      "Epoch -  34 Loss -  0.6990953280604367\n",
      "Epoch -  35 Loss -  0.6990930016892543\n",
      "Epoch -  36 Loss -  0.6990906762928432\n",
      "Epoch -  37 Loss -  0.6990883518707602\n",
      "Epoch -  38 Loss -  0.699086028422563\n",
      "Epoch -  39 Loss -  0.6990837059478084\n",
      "Epoch -  40 Loss -  0.6990813844460546\n",
      "Epoch -  41 Loss -  0.699079063916859\n",
      "Epoch -  42 Loss -  0.6990767443597797\n",
      "Epoch -  43 Loss -  0.6990744257743753\n",
      "Epoch -  44 Loss -  0.699072108160204\n",
      "Epoch -  45 Loss -  0.6990697915168249\n",
      "Epoch -  46 Loss -  0.6990674758437966\n",
      "Epoch -  47 Loss -  0.6990651611406782\n",
      "Epoch -  48 Loss -  0.6990628474070294\n",
      "Epoch -  49 Loss -  0.6990605346424095\n",
      "Epoch -  50 Loss -  0.6990582228463785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.09994267, 0.09984548],\n",
       "        [0.09994272, 0.09984548]]),\n",
       " 'b1': array([[-3.38405750e-05],\n",
       "        [-3.38419977e-05]]),\n",
       " 'W2': array([[0.09920806],\n",
       "        [0.09920816]]),\n",
       " 'b2': array([[0.09915209]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs implementation\n",
    "# loss = - (y log(y_hat) + (1-y) log(1-y_hat))\n",
    "\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "epochs = 50\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  Loss = []\n",
    "\n",
    "  for j in range(df.shape[0]):\n",
    "\n",
    "    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "    y = df[['placed']].values[j][0]\n",
    "\n",
    "    # Parameter initialization\n",
    "\n",
    "\n",
    "    y_hat,A1 = L_layer_forward(X,parameters)\n",
    "    y_hat = y_hat[0][0]\n",
    "\n",
    "    update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "    Loss.append(-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))    # loss = - (y log(y_hat) + (1-y) log(1-y_hat))\n",
    "\n",
    "  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a235858",
   "metadata": {},
   "source": [
    "#### **Note**: If you see the above loss is contant in each epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed3c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ca6cf7",
   "metadata": {},
   "source": [
    "## Keras Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0851df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20e3fe18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  placed\n",
       "0     8              8       1\n",
       "1     7              9       1\n",
       "2     6             10       0\n",
       "3     5              5       0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[8,8,1],[7,9,1],[6,10,0],[5,5,0]], columns=['cgpa', 'profile_score', 'placed'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01ca74fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 23:37:57.961551: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-14 23:37:57.961914: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-14 23:37:58.024973: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-14 23:37:59.535002: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-14 23:37:59.535961: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/home/rohit/Desktop/.conda/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca358e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Desktop/.conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768414102.992677 3520304 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1768414103.013223 3520304 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=2, activation='sigmoid'))  # Hidden layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b426e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f6dd9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.78021514,  0.92057526],\n",
       "        [ 0.9199983 , -0.6783301 ]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[-0.9121893 ],\n",
       "        [-0.15020192]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47d0c738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = [np.ones((2,2))*0.1, np.zeros((2,)), np.ones((2,1))*0.1, np.zeros((1,))]\n",
    "model.set_weights(new_weights)\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58f48cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0397c09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.7653"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6937 \n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6939\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6936\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6936 \n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6938 \n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6937\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6936 \n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6935\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6935\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6937 \n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6934 \n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6934\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6935 \n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6936\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6935\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6935\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6934 \n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6933 \n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6933\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6933 \n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6933\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6933 \n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6934\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6932 \n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6932\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6932\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6932 \n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6931 \n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6933 \n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6931 \n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6932\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6931 \n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6932 \n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6932\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6933 \n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6931\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6931\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6930 \n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6930 \n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6929 \n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6930 \n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6930 \n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6929\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6929\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6929\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6931 \n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6930 \n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6930 \n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6928 \n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b3868296e10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df[['cgpa', 'profile_score']].values, df[['placed']].values, epochs=50, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142d098",
   "metadata": {},
   "source": [
    "### **Note:** Keras also not able to converge the loss in this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14e078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
